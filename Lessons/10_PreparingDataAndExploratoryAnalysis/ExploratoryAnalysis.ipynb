{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "For this example, I downloaded several data sets on health, economy, and education from [Gapminder](http://www.gapminder.org/data/). The data are in excel files, and all files are located in the subdirectory \"data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First read in each data set into a separate dataframe\n",
    "# The dataframes will be stored in a dictionary with the filename as the key\n",
    "data = {}\n",
    "datadir = os.path.join(\"data\", \"gapminder\")\n",
    "for fname in os.listdir(datadir):\n",
    "    dfname = fname.rstrip(\".xls\")\n",
    "    data[dfname] = pd.read_excel(os.path.join(datadir, fname), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's see what we have\n",
    "# To display multiple lines of output, we need to use the print function.\n",
    "print(\"dataframes:\", data.keys())\n",
    "for k,v in data.items():\n",
    "    print(\"name:\", k)\n",
    "    print(\"columns:\", v.columns)\n",
    "    print(\"index (row name):\", v.index)\n",
    "\n",
    "    \n",
    "# Scroll through the output below and you will see that each data set has a column for each year of data\n",
    "# and the rows correspond to countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean\n",
    "A good data cleaning step here is to check that the country names are consistant and to make the dataframe names shorter, without spaces, because in future steps these will become column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Examine the names\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a dictionary that maps old names to new names.\n",
    "# Note that renaming would have been more effiently done at time of download, but this way we have a record of it.\n",
    "namemap = {'GDPpercapitaconstant2000US':'gdp_per_capita',\n",
    "            'indicatorwdigdp_percapita_growth':'gdp_growth_per_capita',\n",
    "            'indicator life_expectancy_at_birth':'life_expectancy',\n",
    "            'indicator_government share of total health spending':'health_spending_govt_share',\n",
    "            'indicator_population density (per square km)':'population_density',\n",
    "            'indicator_per capita government expenditure on health at average exchange rate (us$)':'health_spending_govt_percap',\n",
    "            'Internet user per 100':'internet_use'}\n",
    "for k,v in namemap.items():\n",
    "    data[v] = data.pop(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Check the country names to verify they are consistant among all the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge\n",
    "\n",
    "I want to find the most recent year with data in all data sets, then merge the data for just that year from all the data sets into one dataframe. \n",
    "\n",
    "Some of the years are represented as strings, and others as integers. For sucessful operations, we need to make this consistant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for v in data.values():\n",
    "    v.columns = [int(c) for c in v.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years = [set(v.columns) for v in data.values()]\n",
    "overlap = years[0]\n",
    "for y in years[1:]:\n",
    "    overlap = overlap.intersection(y)\n",
    "max(list(overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dataframe with 2005 data from all the datasets, using the dataframe key as the column name\n",
    "# Pandas has a merge function for two data frames, but I think in this instance it is easier to pull out the desired \n",
    "# columns and make a new one that way.\n",
    "data2010 = pd.DataFrame(dict([(k, v[2010]) for k,v in data.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2010.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop nans because graphing package seaborn doesn't handle them.\n",
    "data2010_nonan = data2010.dropna()\n",
    "data2010_nonan.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.pairplot(data2010_nonan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Identify non-linear relationships from the above matrix of scatter plots. Make new features by transforming variables that create linear relationships. Make scatter plots of the new features to verify the linearity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise\n",
    "View the pandas documentation on the [merge](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) function. Use it to merge two of the available dataframes. Note that due to a conflict in the column names, you should first rename the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bin variables by percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pandas qcut will give quartiles, or any number of equally sized bins\n",
    "quartlabels = [\"25th percentile\", \"50th percentile\", \"75th percentile\", \"100th percentile\"]\n",
    "data2010[\"life_expectancy_quartiles\"] = pd.qcut(data2010[\"life_expectancy\"], 4, labels=quartlabels)\n",
    "data2010[\"population_density_quartiles\"] = pd.qcut(data2010[\"population_density\"], 4, labels=quartlabels)\n",
    "\n",
    "tenthlabels = [\"{:n}th percentile\".format(p) for p in range(10,101,10)]\n",
    "data2010[\"gdp_tenths\"] = pd.qcut(data2010[\"gdp_per_capita\"], 10, labels=tenthlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create some contingency tables\n",
    "density_gdp_table = pd.crosstab(data2010[\"population_density_quartiles\"], data2010[\"gdp_tenths\"])\n",
    "life_gdp_table = pd.crosstab(data2010[\"life_expectancy_quartiles\"], data2010[\"gdp_tenths\"])\n",
    "life_density_table = pd.crosstab(data2010[\"life_expectancy_quartiles\"], data2010[\"population_density_quartiles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "density_gdp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "life_gdp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "life_density_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make a mosiac plot\n",
    "from statsmodels.graphics.mosaicplot import mosaic as statsmodels_mosaic\n",
    "fig, rects = statsmodels_mosaic(data2010, [\"population_density_quartiles\",\"life_expectancy_quartiles\"] )\n",
    "fig.get_axes()[0].set_xlabel(plottable.index.names[0])\n",
    "fig.get_axes()[0].set_ylabel(plottable.index.names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scatter plot example in lecture\n",
    "plt.scatter(data2010[\"health_spending_govt_percap\"], data2010[\"life_expectancy\"])\n",
    "plt.xlabel(\"health_spending_govt_percap\")\n",
    "plt.ylabel(\"life_expectancy\")\n",
    "plt.title(\"Scatter Plot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
